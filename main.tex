\documentclass[10pt, a4paper]{article}
\usepackage[italian]{babel}
\usepackage{helvet}
\renewcommand{\familydefault}{\sfdefault}
\usepackage{setspace}
\usepackage{amsmath}
\usepackage[margin=1in]{geometry}
\usepackage{subcaption}
\usepackage{lipsum} 
\usepackage{graphicx} % Required for inserting images
\usepackage{listings}
\usepackage{hyperref}
\usepackage{amsmath, amssymb}
\usepackage{multirow}
\usepackage{arydshln}
\hypersetup{
    colorlinks=true,     % Abilita i collegamenti colorati
    linkcolor=black,      % Colore dei collegamenti interni
    citecolor=green,     % Colore dei collegamenti alle citazioni
    urlcolor=magenta     % Colore dei collegamenti URL
}

\title{Relazione Software Testing}
\author{Luca Falasca 0334722}

\begin{document}
\date{}
\maketitle


\thispagestyle{empty}
\tableofcontents
\listoftables
\listoffigures

\maxdeadcycles=600

\thispagestyle{empty}
\newpage
\setcounter{page}{1}
\section{Introduction}
Questa relazione descrive il lavoro di testing e di analisi di metriche di coverage
 effettuati sui due progetti open source BookKeeper e Avro.
Per ogni progetto sono state prese in considerazione due classi, e per ognuna di esse
si è fatto un lavoro di stesura di casi di test per poi andare a valutare l'adeguatezza
tramite diverse metriche di coverage. \\
La struttura di ogni analisi è formata dai seguenti punti: 
\begin{itemize}
  \item Descrizione della classe e del metodo preso in considerazione
  \item Category Partition
  \item Boundary Analysis
  \item Adequacy Control Flow
  \item Adequacy Data Flow
  \item Mutation Testing
  \item Reliability
\end{itemize}
Per ognuna delle fasi (ad eccezioni delle prime due), se ritenuto necessario, sono state effettuate delle modifiche
alla test suite basate sulle metriche di coverage calcolate, in modo da migliorare l'adeguatezza dei casi di test.\\ \\
I framework utilizzati per calcolare la coverage sono Jacoco, Badua e Pitest. Essi sono stati
implementati anche come CI sul repository github utilizzando le github actions. \\ 
I fork dei repository su cui è stato effettuato il lavoro di testing sono:
\begin{itemize}
  \item \href{https://github.com/LucaFalasca/bookkeeper}{Bookkeeper}
  \item \href{https://github.com/LucaFalasca/avro}{Avro}
\end{itemize} 

\section{Bookkeeper}
\subsection{Journal}

\subsubsection{Descrizione}
\textbf{Path:} org.apache.bookkeeper.bookie.Journal.java \\
\textbf{Metodo considerato:} listJournalIds \\ \\
\textbf{Documentazione a disposizione:} \\
Lists all journal IDs filtered by a specified journal ID filter.

This method scans the given directory containing journal log files and extracts
journal IDs based on the provided filter. If no filter is provided, all journal
IDs present in the directory are returned.


\paragraph{Input:}
\begin{itemize}
  \item journalDir journal dir : The directory containing journal log files.
  \item filter journal id filter
\end{itemize}
\paragraph{Output:}
    list of filtered ids

\subsubsection{Category Partition}

La category partition del metodo listJournalIds è descritta nella tabella \ref{tab:categoryPartitionListJournalIds}. \\
Siccome la variabile journalDir è il path di una directory, ho partizionato 
il dominio in base al contenuto della directory e al suo effettivo utilizzo, rendendo la scelta delle partizioni 
una conseguenza del fatto che il metodo lavora su file di log.

\subsubsection{Boundary Analysis}
Andiamo a definire per ogni partizione i Boundary values. I valori scelti sono 
descritti nella tabella \ref{tab:boundaryAnalyisListJournalIds}. \\ \\
Per quanto riguarda il valore JournalRollingFilter, esso è l'unico filtro esistente utilizzato nell'applicazione, 
tuttavia siccome viene utilizzato in un contesto molto specifico dell'applicazione e non è un filtro generico, l'ho rimpiazzato
con una sua versione semplificata più generale. Altrimenti non sarebbe stato adatto ad un test di unità, ma sarebbe stato 
più un test di integrazione. \\ \\
Per quanto riguarda il valore MyFilter, esso è un filtro personalizzato creato appositamente per questo test che va a filtrare i journal
in base al loro nome, in particolare se il journalId è \textgreater 0 viene accettato, altrimenti no. 
Questo filtro ha lo scopo di testare come si comporta il sistema in caso di definizione di un nuovo filtro non già esistente 
nel sistema e quindi non è importante il tipo di filtraggio che fa. \\ \\
Siccome i due parametri di input sono abbastanza scorrelati tra loro ha più senso adottare un approccio 
unidimensionale piuttosto che uno multidimensionale che sarebbe più adatto quando ci sono delle interazioni forti
e che portano alla necessità di testare tutte le combinazioni tra i parametri. Inoltre avendo un approccio multidimensionale
si finirebbe probabilemente per avere molti test non rilevanti e vanno a coprire scenari già coperti, e quindi sarebbero inutili.
\\ Enumeriano ora i casi di test derivanti da quest prima analisi (Tabella \ref{tab:categoryPartition1ListJournalIds}) \\ \\
Codice sorgente di JournalTest (Figura \ref{fig:code1})

\subsubsection{Adequacy Control Flow}
Ora per verificare l'adeguatezza dei casi di test, vado a definire dei criteri di adeguatezza. 
Dalla documentazione sappiamo che questo metodo ricava gli id dei journal in una 
determinata cartella, filtrandoli in base ad un filtro specificato, se non viene specificato 
nessun filtro, allora vengono restituiti tutti gli id dei journal presenti nella cartella. \\
La Figura \ref{fig:listJournalIdsCFG} mostra un diagrammma 
funzionale del metodo listJournalIds.
A partire da questo definisco i seguenti criteri di adeguatezza:
\begin{itemize}
  \item almeno un test con un filtro
  \item almeno un test senza filtro
  \item almeno un test senza journal nella cartella
  \item almeno un test con almeno un journal nella cartella
\end{itemize}
In questo caso i criteri di adeguatezza sono già stati soddisfatti 
dai casi di test precedentemente descritti. \\ \\
Dal diagramma precedente possiamo 
ricavare un control flow graph (Figura \ref{fig:listJournalIdsCFG}), per poi
utilizzare dei criteri di copertura basati sul control flow. \\
Dato che in questa fase sto adottando un approccio black box e quindi non sto utilizzando il codice sorgente
per verificare l'adeguatezza dei casi di test, ipotizzo in base agli input se un caso di test andrà a coprire
un certo arco del CFG o meno. Per lo stesso motivo sto quindi basando questa parte dell'analisi esclusivamente sulla funzionalità del metodo, 
e dunque eviterò di utilizzare la coverage come parametro di adeguatezza, in quanto non è possibile ricavare
dall'output del metodo se un certo arco è stato coperto o meno, ma solo se il risultato è corretto oppure no.
Quindi valuterò la copertura del CFG solo in una fase successiva, quando prenderò in considerazione
anche il codice sorgente (approccio whitebox), utilizzando la coverage come parametro di adeguatezza.
Quello che farò in questa fase è quindi valutare se i casi di test che ho definito in precedenza
coprono tutti gli archi del CFG, in base alla mia conoscenza del metodo e dei suoi input, e nel caso
aggiungere quelli mancanti. \\
Arco (1,2)  $\rightarrow$  Tutti i test che hanno almeno un file di log coprono questo caso, quindi non è necessario aggiungere ulteriori test. \\
Arco (2,3)  $\rightarrow$ Tutti i test che hanno almeno un file di log e un filtro non null coprono questo caso, quindi non è necessario aggiungere ulteriori test. \\
Arco (2,4)  $\rightarrow$ Questo arco non è coperto perchè manca un test che abbia almeno un file di log e il filtro null. Basta quindi aggiungere il 
test necessario (Figura \ref{tab:ACF1ListJournalIds}). \\
Arco (3,4)  $\rightarrow$ Tutti i test che hanno almeno un file di log e un filtro non null coprono questo caso, quindi non è necessario aggiungere ulteriori test. \\ 
È stato necessario quindi aggiungere un caso di test e quindi la attuale test suite è descritta nella Tabella \Ref{tab:ACF2ListJournalIds} \\ \\
Ora andiamo a valutare la coverage ottenuta con jacoco con i casi di test definiti fino ad ora (Figura \ref{fig:listJournalIds_jacoco}). 
Come si può vedere dalla figura \ref{fig:listJournalIds_jacoco},
la statement coverage è del 100\% (colonna missed instruction), 
e quindi tutte le linee di codice del metodo sono state eseguite. \\
Invece la condition coverage (colonna missed branches) e del 83\%, ed è quindi migliorabile.
Andando a vedere in dettaglio il report, si può notare che una condizione che non è stata coperta
è una delle 4 combinazioni dell'if a riga 106 come si vede dalla Figura \ref{fig:listJournalIds_jacoco2}.
La condizione presa in esame è la seguente:
\begin{verbatim}
logFiles == null || logFiles.length == 0
\end{verbatim}
il branch mancato è quello dove logFiles == null, questo perchè se il parametro di input journalDir è null non esegue proprio il metodo listFiles().
Questo è dovuto al fatto che il path non era esistente e quindi il metodo tornava null.
Andiamo quindi a definire un caso di test che copra questo branch
Per farlo andiamo semplicemente basta aggiungere un category partition che copre il caso di una cartella esistente ma vuota
(Tabella \ref{tab:ACF3ListJournalIds}). Ora quindi l'insieme dei test è quello mostrato nella tabella \ref{tab:ACF4ListJournalIds}, 
e grazie a questo test la condition coverage è salita al 91\% (Figura \ref{fig:listJournalIds_jacoco3}),
con un aumento del 8\%.

 \subsubsection{Adequacy Data Flow}

 Andiamo ora ad fare un lavoro di adeguatezza del dataflow utilizzando il framework badua per calcolare la all-uses coverage. \\
Dalla Figura \ref{fig:listJournalIds_badua} possiamo calcolare la all uses coverage. \\
\(CU_c + PU_c = 18\) \\
\( (CU + PU) - (CU\textsubscript{f} + PU\textsubscript{f}) = 18 + 2 = 20\) \\ \\
\[\frac{{CU\textsubscript{c} + PU\textsubscript{c}}}{{(CU + PU) - (CU\textsubscript{f} + PU\textsubscript{f})}} = \frac{{18}}{{20}} = 0.9\]

Ci sono quindi 2 coppie def-use che non sono state coperte, e quindi la all uses coverage è del 90\%.
Per aumentare la coverage è necessario aggiungere un caso di test che copra almeno una di queste coppie.
Prendiamo in considerazione la coppia def-use sulla variabile filter non coperta. Si tratta di una coppia c-use 
dove il target è il continuo del ciclo for in cui è contenuto lo statement. In effetti non c'è nessun caso di test
che va a coprire il caso in cui la coppia def-use è coperta e successivamente continua il ciclo.
Per fare ciò vado ad aggiungere un caso di test che continua il ciclo for una volta rifiutata 
l'espressione booleana in cui è contentuto il comando. Per fare ciò basta aggiungere una cartella in cui controlla
un altro id di journal dopo averne rifiutato uno. Effettivamente badua è servito a migliorare la qualità dei 
test perchè nonostante la coverage
coprisse già queste righe di codice non era stata in grado di intercettare la mancanza
di test su questo comportamento. \\
Il caso di test è descritto nella Tabella \ref{tab:ADF1ListJournalIds}. Quello che ho fatto è creare una nuova
cartella che contiene due file di log e un filtro con condizione \textgreater1, il primo dei due file viene rifiutato 
e il secondo invece viene accettato. In questo modo il metodo dopo aver scartato il primo file di log, continua
con la sua ricerca e trova il secondo file di log che viene accettato. In questo modo la coppia
def-use sulla variabile filter viene coperta e la all uses coverage sale (Figura \Ref{fig:listJournalIds_badua2}).
Con questo caso di test vado a coprire anche l'altra coppia def-use che non era stata coperta.
Questo succede perchè anche a lei mancava il caso in cui una volta che il filtro rifiutava un id il
metodo continuava la sua ricerca e trovava un id successivo.
Così la all-use coverage riesce a raggiungere il 100\%. Inoltre come effetto secondario si può notare che anche
la condition coverage è salita al 100\% (Figura \ref{fig:listJournalIds_jacoco4})

\subsubsection{Mutation Testing}
Andiamo ora a fare un lavoro di adeguatezza utilizzando il framework pitest per calcolare la mutation coverage. 
Come si può notare dalla Figura \ref{fig:listJournalIds_pitest} vengono rilevate tutte le mutazioni tranne 1.
Quindi possiamo calcolare la mutation coverage come segue:
\[\frac{{Mutazioni rilevate}}{{Mutazioni totali}} = \frac{{6}}{{7}} = 0.85\]
Prendiamo in considerazione quindi la mutazione a riga 125, che non viene rilevata dalla test suite. Si tratta 
di una mutazione che omette la riga che si occupa di ordinare la lista di file di log. \\

Per aumentare la coverage vado quindi a modificare la test suite per coprire anche la mutazione a riga 125.
Siccome la copertura manca perchè nei test correnti non viene mai ritornato un log con dimensione \textgreater1, e 
quindi non c'è niente da ordinare. In particolare nel test che andrò ad aggiungere andrò a creare una cartella con 2 file
di log che hanno id descrescente, in questo modo il metodo ordina i file di log e quindi la mutazione viene rilevata.
Tuttavia ciò non è possibile perchè quando si vanno ad inserire dei file in una cartella essi vengono ordinati già in ordinare
alfabetico e quindi quando vengono presi sono già ordinati. Non è quindi possibile naturalmente creare una situazione 
in cui i file che vengono presi dalla cartella tramite il metodo listFiles\(\) non siano già ordinati. \\
Quindi ci sono due strade da poter percorrere:
\begin{itemize}
  \item Andare ad etichettare l'implementazione del metodo senza la riga 112 (la riga che si occupa di ordinare la lista) 
  come equivalente a quella senza la riga, e quindi non considerare la mutazione valida perchè è un codice che non
  comporta nessun cambiamento.
  \item Ipotizzare che in futuro possa esserci un caso in cui la lista non è ordinata, dovuto ad un cambiamento del codice
  della libreria, oppure ad un sistema operativo diverso. Quindi andare a creare una situazione impossibile tramite mock per
  verificare questa eventualità.
\end{itemize} 
Ho scelto di intraprendere la seconda strada perchè mi sembra la più manutenibile, vado quindi a mockare 
il metodo listFiles\(\), in modo tale che una volta aver recuperato i file li vada a 
ordinare in modo decrescente (Figura \ref{fig:code2}), in modo da simulare il comportamento non altrimenti possibile nelle condizioni attuali. \\
Ora effettivamente la mutazione viene rilevata (Figura \ref{fig:listJournalIds_pitest}), e quindi la mutazione viene rilevata.
Quindi tutte le mutazioni sono state rilevate e quindi la mutation coverage è del 100\% 

\subsubsection{Reliability}
Considero come profili operazionali gli input della test suite sviluppata perchè essi sono derivanti dalle classi di equivalenza
e quindi sono la migliore rappresentazione a mia disposizione dei possibili input del sistema. Inoltre non ho documentazione che
mi permette di concludere che un caso sia più o meno probabile di un altro e quindi li considero equiprobabili. Date queste 
assunzioni e siccome questi test non rilevano nessuna failure del sistema, la reliability in questo caso è 1. Ciò, tuttavia,
 non significa che non siano presenti bug che la mia test suite non è stata in grado di rilevare.

\subsection{FileInfo}
\subsubsection{Descrizione}
\textbf{Path:} org.apache.bookkeeper.bookie.FileInfo.java \\
\textbf{Metodo considerato:} readHeader \\ 
\textbf{Descrizione metodo:} Legge l'header di un ledger index file per verificarne la correttezza.
Lancia una eccezione se l'header non è corretto, altrimenti non ritorna nulla.\\ \\
Come input prende ovviamente il file di cui deve leggere l'header. Tuttavia per rendere la category partition più sensata
vado a considerare l'input come le componenti di cui è formato l'header, ovvero:
\paragraph{Input:}
\begin{itemize}
  \item magic bytes
  \item len of master key
  \item master key
\end{itemize}

\subsubsection{Category Partition}
\textbf{Magic Bytes:} \{valido\}, \{non valido\}, \{null\} \\
\textbf{Master key:} \{null\}, \{master key di 0 byte\}, \{master key di \textgreater 0 byte\} \\
\textbf{Len of master key:} \{ = len master key\} \{\textless len master key\} \{\textgreater len master key\} \{null\} \\ \\
Siccome in documentazione non c'è scritto niente su questo stato dell'header, ho abbandonato momentaneamente
l'approccio black box sulla category partition di questo parametro, e andando a controllare nel codice
ho scoperto che nella classe viene solamente controllato se lo stato è fenced o non fenced, quindi ho descritto 
la category partition in questo modo: \\
\textbf{state:} \{null\} \{fenced\} \{non fenced\} \\


\subsubsection{Boundary Analysis}
Andiamo a definire per ogni partizione i Boundary values (Figura \ref{tab:boundaryAnalyisReadHeader1} e Figura \ref{tab:boundaryAnalyisReadHeader2}). 
Nell'header c'è un campo che indica la versione, non specificato nella documentazione, ma
analizzando il codice si può notare che ne esistono due tipi, la versione 0 e la versione 1. Per questo motivo
vado a specificare anche una category partition e boundary analisys per questo campo, in modo tale da poter testare entrambe le versioni. \\

Andrò ad utilizzare un approccio unidimensionale nella stesura dei casi 
di test, tranne per le coppie di parametri master key e len of master key,
che essendo strettamente correlate ho ritenuto opportuno testare tutte le 
combinazioni tra loro.
I casi di test sono specificati nella Tabella \ref{tab:categoryPartition1ReadHeader}.
Codice implementato Figura \ref{fig:Code1ReadHeader}. \\ \\
Andando ad eseguire questi test molti di questi falliscono (Figura \Ref{fig:TestFailsReadHeader}), andiamo a documentare perchè reputo 
dei bug i fallimenti di questi test. \\
Il primo test che fallisce è il numero 1. Fallisce perchè ho ritenuto opportuno che se il campo dell'header 
che indica la lunghezza della master key mandi un eccezione nel caso in cui non coincida con la lunghezza effettiva 
della masterkey inserita, invece il metodo non si accorge di niente.
Anche i test 2 e 5 falliscono per la stessa motivazione. 
Invece per quanto riguarda il test 3, questo fallisce perchè ritorna un eccezione anche se non dovrebbe. 
L'eccezione descrive il fatto che -1 non è una lunghezza accettata per la masterkey, tuttavia nella documentazione è
esplecitamente specificato che -1 indica il fatto che non viene specificata nessuna master key, esattamente come viene 
fatto nel caso di test considerato. 
Nonostante questi casi falliscano per andare avanti con l'analisi e per non falsare i dati di coverage calcolati
dai framework li andrò a modificare facendoli passare (anche se non dovrebbero).


\subsubsection{Adequacy Control Flow}
Ora per verificare l'adeguatezza dei casi di test, vado ad utilizzare
Jacoco per calcolare la coverage. Come si può vedere della figura \ref{fig:JacocoCoveragereadHeader1} con questa test suite otteniamo
una statement coverage del 61\% e una condition coverage del 59\%. \\
Andando ad analizzare in maniera più specifica quali sono le parti non coperte (Figura \ref{fig:JacocoCoveragereadHeader2})
si può notare a riga 243 che se si usa la versione V1 dell'header è possibile specificare una parte aggiuntiva dell'header
chiamata explicitLacBufLength. \\
Sono andato quindi ad aggiungere un valore di input ai test e due casi di test per coprire questo input aggiuntivo. \\
Category Partition explicitLacBufLength $\rightarrow
\{ >= \text{LAC\_METADATA\_LENGTH} \}, \\
\{ <  \text{LAC\_METADATA\_LENGTH}\quad \textrm{AND} \quad >= 0\}, 
\{ < 0 \}$ 

Essendo il campo specificato come length, mi è sembrato opportuno descrivere anhe il caso in cui la lunghezza è negativa.
Nel caso d'uso del programma $\text{LAC\_METADATA\_LENGTH}$ è impostato in maniera final come 16, quindi andando a fare una boundary
analysis su questo parametro ottengo i seguenti valori:

\paragraph{explicitLacBufLength}
\begin{itemize}
  \item \{ \textgreater= 16 \} = 16
  \item \{ \textless 16 AND \textgreater= 0 \} = 15, 0
  \item \{ \textless 0 \} = -1
\end{itemize}
La test suite ora è composta in questo modo: (Tabella \ref{tab:TestSuiteReadHeader2}). \\
Grazie a questo incremento la statement coverage è salita al 82\%
e la condition coverage al 77\% (Figura \ref{fig:JacocoCoveragereadHeader3})



\subsubsection{Adequacy Data Flow}

Andiamo ora a fare un lavoro di adeguatezza del dataflow utilizzando il framework badua per calcolare la all-uses coverage. \\
Dalla Figura \ref{fig:BaduaCoverageReadHeader1} possiamo calcolare la all uses coverage. \\

\(CU_c + PU_c = 66\) \\
\( (CU + PU) - (CU\textsubscript{f} + PU\textsubscript{f}) = 66 + 16 = 82\) \\ \\
\[\frac{{CU\textsubscript{c} + PU\textsubscript{c}}}{{(CU + PU) - (CU\textsubscript{f} + PU\textsubscript{f})}} = \frac{{66}}{{82}} = 0.8\]
Prendendo in considerazione le coppie def-use in Figura \ref{fig:BaduaCoverageReadHeader2} possiamo notare che
effettivamente la test suite non copre la coppia def-use sulla variabile version dalla riga 226 alla riga 228.
Andiamo quindi a generare un caso di test che copra questa coppia def-use. \\ \\
Per fare ciò andiamo a modificare il test che copre la versione 0 dell'header, aggiungendo un caso in cui la versione
è 2 (Tabella \ref{tab:ADF1ReadHeader}).  Rifacendo la build con Badua si può notare che la coppia def-use ora risulta coperta (Figura \ref{fig:BaduaCoverageReadHeader3})
e c'è stato un incremento delle coppie def-use coperte (Figura \ref{fig:BaduaCoverageReadHeader4}). Ricalcolando
la all-uses coverage 
\(CU_c + PU_c = 69\) \\
\( (CU + PU) - (CU\textsubscript{f} + PU\textsubscript{f}) = 69 + 12 = 82\) \\ \\
\[\frac{{CU\textsubscript{c} + PU\textsubscript{c}}}{{(CU + PU) - (CU\textsubscript{f} + PU\textsubscript{f})}} = \frac{{69}}{{82}} = 0.84\]
si può notare che la all-uses coverage è salita al 84\% \\

\subsubsection{Mutation Testing}
Vado ora a fare un analisi delle mutazioni utilizzando il framework pitest. \\
Come si può vedere dalla Figura \ref{fig:PitCoverageReadHeader1} la mutation coverage è del 10\% in riferimento all'intera classe.
Se invece andiamo a vedere in dettaglio il metodo readHeader (Figura \Ref{fig:PitCoverageReadHeader2}), la mutation coverage è 
\[\frac{{Mutazioni rilevate}}{{Mutazioni totali}} = \frac{{15}}{{16}} = 0.93\]



Prendiamo in considerazione per migliorare la test suite la mutazione non rilveata a riga 235. 
La mutazione (Figura \ref{fig:PitCoverageReadHeader3}) trasforma il \textgreater in \textgreater=.

Per risolvere il problema basterebbe passare come lunghezza della master key un valore che equivale al numero di byte rimanenti
del file. In questo modo la mutazione verrebbe rilevata perchè si riuscirebbe a distinguere il caso in cui è \textgreater da quello in cui
è \textgreater=. Tuttavia la mutazione non viene rilevata perchè anche se la lunghezza della master key dichiarata fosse uguale alla
lunghezza rimanente, l'header contiene degli altri campi che vengono letti dopo la master key che generano la stessa eccezione 
che genererebbe il codice in quel caso. Quindi non è possibile rilevare la mutazione in questo modo. \\
Inoltre il controllo a riga 235 con relativo lancio dell'eccezione è superfluo, perchè quando successivamente si tenta la lettura
se la lunghezza dei byte che si vogliono leggere è maggiore della lunghezza rimanente del file, viene lanciata la stessa eccezione
già dalla libreria di java. Quindi posso considerare il codice equivalente anche senza questo blocco di codice. \\
In questo modo posso considerare la mutation coverage del 100\%.

\subsubsection{Reliability}
Considero come profili operazionali gli input della test suite sviluppata perchè essi sono derivanti dalle classi di equivalenza
e quindi sono la migliore rappresentazione a mia disposizione dei possibili input del sistema. Inoltre non ho documentazione che
mi permette di concludere che un caso sia più o meno probabile di un altro e quindi li considero equiprobabili. Date queste 
assunzioni nella mia test suite sono risultate 4 failure su un totale di 11 profili operazionali, quindi la reliability è del 63\%.

\newpage
\section{Avro}
\subsection{Schema}
\subsubsection{Descrizione}
La classe Schema è una classe astratta che rappresenta uno schema Avro. E' una delle classi core di Avro, e viene utilizzata
per rappresentare i dati serializzati. \\ \\
\textbf{Path:} org.apache.avro.Schema.java \\
\textbf{Metodo considerato:} createRecord() \\
\textbf{Descrizione metodo:} che si occupa di creare uno schema di tipo record 
\paragraph{Input:} name, doc, namespace, isError, fields

\paragraph{Output:} Schema \\ \\
La documentazione è in Figura \ref{fig:Documentation}.

\subsubsection{Category Partition}
La category partition del metodo createRecord è descritta nella tabella \ref{tab:categoryPartitionCreateRecord}.
Il campo name rappresenta il nome dello schema e siccome è obbligatorio ho partizionato in modo da testare questa caratteristica.
Stessa discorso ma speculare vale per il campo doc e namespace, dato che sono descritti come opzionali 
quindi andranno testati in maniera differente.
Per quanto riguarda il campo isError, esso non è descritto nella documentazione, quindi essendo un campo booleano
ho deciso di partizionarlo in modo da testare entrambi i valori.\\
Il campo fields essendo un vettore di elementi, ho deciso di partizionarlo in modo da testare i casi in cui il vettore
è vuoto, contiene un solo elemento e contiene più di un elemento. Ho deciso di non addentrarmi nella specifica di 
questi elementi, in quanto sarebbe fuori contesto nell'analisi di questo unit test.
\subsubsection{Boundary Analysis}

La Boundary Analysis è descritta nella tabella \ref{tab:BoundaryAnalysisCreateRecord}. 
Da essa ricavo la test suite (Tabella \ref{tab:categoryPartition1CreateRecord}).
Il motivo per cui i test 3 e 4 devono restituire una eccezione è perchè nella documentazione è specificato che
il campo name è obbligatorio, e quindi se non viene specificato deve essere lanciata una eccezione.
Invece il motivo per cui il 5 e 6 test devono restituire una eccezione è perchè nella documentazione è specificato che
fields è obbligatorio, e quindi se non viene specificato deve essere lanciata una eccezione. \\
Come si vede dalla Figura \ref{fig:TestFailsCreateRecord} i test 4 e 6 falliscono. Significa che il metodo non si accorge
che il campo name e fields non sono stati specificati. \\
Vado a modificare i due metodi facendoli passare (anche se non dovrebbero) per poter andare avanti con l'analisi e 
per non falsare i dati di coverage calcolati dai framework.

\subsubsection{Adequacy Control Flow}

Andiamo ora a valutare la coverage ottenuta con jacoco con i casi di test definiti. Per farlo consideriamo il fatto
che in realtà il metodo createRecord() è solo un wrapper di una new della classe interna RecordSchema, quindi per calcolare
la coverage dobbiamo prendere in considerazione il costruttore della classe RecordSchema. \\ Però la vera logica del metodo
è contenuta nel metodo privato setField(). Quindi per fare considerazioni sulla coverage dobbiamo prendiamo in considerazione 
l'insieme di questi metodi. \\ \\
Dalla Figura \ref{fig:JacocoCoverageCreateRecord1} si può vedere che la statement coverage della classe è del 12\%. Tuttavia come 
spiegato in precedenza il metodo createRecord() è solo un wrapper di una new della classe interna RecordSchema che invece ha una
statement coverage del 17\% (Figura \ref{fig:JacocoCoverageCreateRecord2}). Inoltre il costrutture e il metodo setField() 
che rappresenta la vera logica del metodo preso in esame hanno rispettivamente una coverage del 100\% e del 59\% 
(Figura \ref{fig:JacocoCoverageCreateRecord3}). \\ \\
Quindi per migliorare i miei casi di test andrò ad analizzare principalemente il metodo setFied() con un approccio white box.
Data la situazione in Figura \ref{fig:JacocoCoverageCreateRecord4} vado ad incrementare l'adeguatezza dei casi di test
andando a coprire il caso in cui il field ha il campo position = -1. Per farlo dato che per farlo controllava questo branch 
tramite un attributo privato ho fatto in modo di settare questo attributo a -1 tramite reflection.
Quindi ho aggiunto un caso di test che copre questo caso nella test suite (Tabella \ref{tab:Jacoco1CreateRecord}).
Con questo incremento ho ottenuto una coverage del 70\% (Figura \ref{fig:JacocoCoverageCreateRecord5}).


\subsubsection{Adequacy Data Flow}

Vado ora a fare un lavoro di adeguatezza del dataflow utilizzando il framework badua per calcolare la all-uses coverage. \\
Dalla Figura \ref{fig:BaduaCoverageCreateRecord1} possiamo calcolare la all uses coverage. \\
\(CU_c + PU_c = 25\) \\
\( (CU + PU) - (CU\textsubscript{f} + PU\textsubscript{f}) = 33\) \\ \\
\[\frac{{CU\textsubscript{c} + PU\textsubscript{c}}}{{(CU + PU) - (CU\textsubscript{f} + PU\textsubscript{f})}} = \frac{{25}}{{33}} = 0.75\] \\ 
Per migliorare la all-uses coverage andiamo a coprire la coppia def-use (956, 959) della variabile existingField che non 
è stata coperta dai precedenti test. Questa coppia indica la mancanza del caso in cui due field uguali vengono inseriti, 
quindi per coprire la coppia def-use andiamo ad aggiungere un test che manda in input due field uguali 
(Tabella \ref{tab:Badua1CreateRecord}).
Con questo incremento la all-uses coverage è salita al 93\% (Figura \ref{fig:BaduaCoverageCreateRecord2}).
\subsubsection{Mutation Testing}

Vado ora a fare un analisi delle mutazioni utilizzando il framework pitest. \\
Come si può vedere dalla Figura \ref{fig:PitMutationCreateRecord1} la mutation coverage è del 4\% in riferimento 
all'intera classe. Se invece andiamo a vedere in dettaglio il metodo, possiamo lavorare con una mutation coverage 
più a grana fine (Figura \ref{fig:PitMutationCreateRecord2}, \ref{fig:PitMutationCreateRecord3}, \ref{fig:PitMutationCreateRecord4}).
In particolare posso calcolare questa mutation coverage come segue:
\[\frac{{Mutazioni rilevate}}{{Mutazioni totali}} = \frac{{4}}{{6}} = 0.66\] \\
Prendiamo in considerazione per migliorare la test suite la mutazione non rilevata a riga 224 
(Figura \ref{fig:PitMutationCreateRecord2}, Figura \ref{fig:PitMutationCreateRecord5}).
Questa mutazione non viene rilevata perchè fino ad adesso nella test suite ho considerato come expected value o un eccezione
o un successo (che indica semplicemente una non eccezione), quindi il caso in cui viene ritornato null non viene rilevato.
Per risolvere il problema basta modificare la test suite aspettando come valore di ritorno un oggetto di tipo Schema nei casi 
di successo (Tabella \ref{tab:PitCreateRecord1}). \\
Con questo incremento la mutazione viene rilevata (Figura \ref{fig:PitMutationCreateRecord6}), e quindi 
la mutation coverage diventa dell' 83\%. 

\subsubsection{Reliability}
Considero come profili operazionali gli input della test suite sviluppata perchè essi sono derivanti dalle classi di equivalenza
e quindi sono la migliore rappresentazione a mia disposizione dei possibili input del sistema. Inoltre non ho documentazione che
mi permette di concludere che un caso sia più o meno probabile di un altro e quindi li considero equiprobabili. Date queste 
assunzioni nella mia test suite sono risultate 2 failure su un totale di 8 profili operazionali, quindi la reliability è del 75\%.
\subsection{SchemaCompatibility}

\subsubsection{Descrizione}

SchemaCompatibility \\
\textbf{Path:} org.apache.avro.SchemaCompatibility.java \\
\textbf{Metodo considerato:} checkReaderWriterCompatibility \\

Per testare questa classe mi concentrerò sul metodo esposto checkReaderWriterCompatibility che
si occupa di verificare la compatibilità tra due schemi. \\
Partiamo dalla definizione di compatibilità descritta dalla documentazione: \\\\
\textit{Evaluate the compatibility between a reader schema and a writer schema. A
reader and a writer schema are declared compatible if all datum instances of
the writer schema can be successfully decoded using the specified reader 
schema.} \\ \\
\textbf{Input:} reader, writer \\
\textbf{Output:} boolean. \\
In realtà il metodo java effettivo non ritorna un boolean ma un oggetto con una descrizione che segnala se è 
compatibile o meno. Ma dato che il metodo in questione ha lo scopo semplicemente di identificare se due schemi sono compatibili
ho deciso di interpretare il risultato come un booleano.



\subsubsection{Category Partition}


Data la descrizione di compatibilità data dalla documentazione ho interpretato che essa dipenda necessariamente dal tipo 
associato allo schema. Quindi ho deciso di partizionare gli input basandomi su questo criterio. \\
Nella documentazione è specificato che i tipi possono essere di due categorie, o primitivi o derivati.\\ \\
Reader: \{Schema con tipo primitivo\}, \{Schema con tipo derivato\} \\
Dato che il metodo confronta due schemi per controllare la loro compatibilità, ho ritenuto necessario che la category partition
di uno dipendesse dall'altro. In questo modo do importanza alla loro combinazione che ha più rilevanza ai fini del testing.\\ \\
Writer: \{Schema con tipo uguale al reader\}, \{Schema con tipo diverso dal reader\}


\subsubsection{Boundary Analysis}

Reader: \{Schema tipo int\}, \{Schema tipo record\} \\
Writer: \{Schema stesso tipo di Reader\}, \{Schema di tipo diverso da Reader ma stessa categoria\}, \{Schema di tipo diverso da Reader ma categoria diversa\} \\ \\
Test suite (Tabella \ref{tab:TestSuiteSchemaCompatibility})

\subsubsection{Adequacy Control Flow}
Vado ora a valutare la coverage ottenuta con jacoco con i casi di test definiti.
Dalla Figura \ref{fig:JacocoCoverageSchemaCompatibility1} si può vedere che la statement coverage della classe è del 37\%.
Se osserviamo solo il metodo considerato la statement coverage è del 78\% e la condition coverage è del 66\%.
Andando a vedere in maniera più specifica quali sono le parti non coperte (Figura \ref{fig:JacocoCoverageSchemaCompatibility2}),
si può osservare che la parte non coperta è semplicemente il caso di default del costrutto switch.
Tuttavia non è possibile scaturire nessun caso di test che copra questo caso, in quanto non è possibile che il metodo
ritorni un valore diverso nell'implementazione corrente. Quindi sarebbe opportuno mockare qualche parte per permettere
di esplorare questo scenario, tuttavia non è possibile mockare nulla perchè questo comportamento è descritto solamente
tramite l'uso di variabili locali che non sono raggiungibili con i mock. Quindi non è possibile aumentare la coverage
di questo metodo. \\
Vado quindi a considerare la coverage senza la parte non raggiungibile dai casi di test, e quindi entrambe diventano del 100\%
\subsubsection{Adequacy Data Flow}
Andiamo ora a fare un lavoro di adeguatezza del dataflow utilizzando il framework badua per calcolare la all-uses coverage. \\
Dalla Figura \ref{fig:BaduaCoverageSchemaCompatibility1} possiamo calcolare la all uses coverage. \\
\(CU_c + PU_c = 12\) \\
\( (CU + PU) - (CU\textsubscript{f} + PU\textsubscript{f}) = 12 + 3 = 15\) \\ \\
\[\frac{{CU\textsubscript{c} + PU\textsubscript{c}}}{{(CU + PU) - (CU\textsubscript{f} + PU\textsubscript{f})}} = \frac{{11}}{{14}} = 0.8\]

Tutte le coppie use-def non coperte fanno riferimento allo stessa riga non coperta dalla statement coverage, quindi
per gli stessi motivi spiegati precedentemente anche la all-uses coverage è considerabile al 100\%
\subsubsection{Mutation Testing}
Vado ora a fare un analisi delle mutazioni utilizzando il framework pitest. \\
Dalla Figura \ref{fig:PitMutationSchemaCompatibility1} si può vedere che la mutation coverage è del 100\% perchè
pit ha generato una sola mutazione e questa è stata rilevata. \\


\subsubsection{Reliability}
Considero come profili operazionali gli input della test suite sviluppata perchè essi sono derivanti dalle classi di equivalenza
e quindi sono la migliore rappresentazione a mia disposizione dei possibili input del sistema. Inoltre non ho documentazione che
mi permette di concludere che un caso sia più o meno probabile di un altro e quindi li considero equiprobabili. Date queste 
assunzioni e siccome questi test non rilevano nessuna failure del sistema, la reliability in questo caso è 1. Ciò, tuttavia,
 non significa che non siano presenti bug che la mia test suite non è stata in grado di rilevare.

\subsection{IT Schema-SchemaResolver}
Questa sezione descrive l'implementazione di un test di integrazione che utilizza le classi Schema e SchemaResolver.
Il test in questione si occupa di verificare l'integrazione tra il metodo createRecord() della classe Schema (metodo già
analizzato in precedenza) e il metodo unresolvedSchema() della classe SchemaResolver. \\
Il test in questione va semplicemente ad utilizzare il metodo unresolvedSchema() che usa createRecord() per creare uno schema
con delle caratteristiche particolari e verifica che lo schema ritornato abbia effettivamente le caratteristiche richieste. \\
Codice implementato in Figura \ref{fig:CodeIntegrationTest}. \\
Il report di Failsafe mostra che l'integration test è andato a buon fine (Figura \ref{fig:ReportIntegrationTest}).
\newpage
%Tabelle Journal --------------------------------------------------------

\begin{table}[ht]
  \centering
  \caption[Journal: Category Partition]{Category Partition metodo listJournalIds}
  \begin{tabular}{|l|l|}
  \hline
  \multicolumn{1}{|c|}{journalDir} & \multicolumn{1}{|c|}{JournalIdFilter} \\
  \hline
  \{Directory contenente file di log\} & Filtro esistente \\
  \{Directory contenente file di log e altri file\} & Filtro sempre True \\
  \{Directory contenente file non di log\} & Filtro sempre False \\
  \{path non esistente\} & Filtro inesistente \\
  \{Path di un file\} & null \\
  null & \\
  \hline
  \end{tabular}
  \label{tab:categoryPartitionListJournalIds}
\end{table}

\begin{table}[ht]
  \centering
  \caption[Journal: Boundary Analysis]{Boundary Analysis metodo listJournalIds}
  \begin{tabular}{|l|l|}
  \hline
  \multicolumn{1}{|c|}{journalDir} & \multicolumn{1}{|c|}{JournalIdFilter} \\
  \hline
  \{Directory contenente 1 file di log\} & JournalRollingFilter \\
  \{Directory contenente 1 file di log e 1 file di testo\} & Filtro sempre True \\
  \{Directory contenente 1 file di testo\} & Filtro sempre False \\
  \{path non esistente\} & MyFilter \\
  \{Path di un file di log\} & null \\
  null & \\
  \hline
  \end{tabular}
  \label{tab:boundaryAnalyisListJournalIds}
\end{table}

\begin{table}[ht]
  \centering
  \caption[Journal: Test Suite - Category Partition]{Test Suite derivante dalla category partition e dalla boundary analysis}
  \begin{tabular}{|c|c|c|}
  \hline
  journalDir & JournalIdFilter & Risultato Atteso \\
  \hline
  {Directory contenente 1 file di log} & JournalRollingFilter & [1] \\
  {Directory contenente 1 file di log e 1 file di testo} & Filtro sempre True & [1] \\
  {Directory contenente 1 file di testo} & Filtro sempre False & [ ] \\
  {path non esistente} & MyFilter & [ ] \\
  {Path di un file di log} & null & Exception \\
  null & null & Exception \\
  \hline
  \end{tabular}
  \label{tab:categoryPartition1ListJournalIds}
\end{table}



\begin{table}[ht]
  \centering
  \caption[Journal: Test Suite - Adequacy Control Flow 1]{Test per coprire l'arco (2,4)}
  \begin{tabular}{|c|c|c|}
    \hline
journalDir & JournalIdFilter & Risultato Atteso \\
  \hline
    {Directory contenente 1 file di log} & null & Exception \\
    \hline
  \end{tabular}
  \label{tab:ACF1ListJournalIds}
\end{table}

\begin{table}[ht]
  \centering
  \caption[Journal: Test Suite - Adequacy Control Flow 2]{Casi di test aggiornati per coprire l'arco (2,4)}
  \begin{tabular}{|c|c|c|}
  \hline
  journalDir & JournalIdFilter & Risultato Atteso \\
  \hline
  {Directory contenente 1 file di log} & JournalRollingFilter & [1] \\
  {Directory contenente 1 file di log e 1 file di testo} & Filtro sempre True & [1] \\
  {Directory contenente 1 file di testo} & Filtro sempre False & [ ] \\
  {path non esistente} & MyFilter & [ ] \\
  {Path di un file di log} & null & Exception \\
  null & null & Exception \\
  {Directory contenente 1 file di log} & null & Exception \\
  \hline
  \end{tabular}
  \label{tab:ACF2ListJournalIds}
\end{table}

\begin{table}[ht]
  \centering
  \caption[Journal: Test Suite - Adequacy Control Flow 3]{Test per aumentare la condition coverage}
  \begin{tabular}{|c|c|c|}
    \hline
    journalDir & JournalIdFilter & Risultato Atteso \\
    \hline
    {Directory vuota} & null & [ ] \\
    \hline
  \end{tabular}
  \label{tab:ACF3ListJournalIds}
\end{table}

\begin{table}[ht]
  \centering
  \caption[Journal: Test Suite - Adequacy Control Flow 4]{Casi di test aggiornati per aumentare la condition coverage}
  \begin{tabular}{|c|c|c|}
  \hline
  journalDir & JournalIdFilter & Risultato Atteso \\
  \hline
  {Directory contenente 1 file di log} & JournalRollingFilter & [1] \\
  {Directory contenente 1 file di log e 1 file di testo} & Filtro sempre True & [1] \\
  {Directory contenente 1 file di testo} & Filtro sempre False & [ ] \\
  {path non esistente} & MyFilter & [ ] \\
  {Path di un file di log} & null & Exception \\
  null & null & Exception \\
  {Directory contenente 1 file di log} & null & Exception \\
  {Directory vuota} & null & [ ] \\
  \hline
  \end{tabular}
  \label{tab:ACF4ListJournalIds}
\end{table}

  \begin{table}[ht]
    \centering
    \caption[Journal: Test Suite - Adequacy Data Flow 1]{Test per aumentare la all-use coverage}
    \begin{tabular}{|c|c|c|}
      \hline
      journalDir & JournalIdFilter & Risultato Atteso \\
      \hline
      {Directory con un log con id 2 e un file con id 1} & {Filtro con condizione \textgreater1} & [2] \\
      \hline
    \end{tabular}
    \label{tab:ADF1ListJournalIds}
  \end{table}

  \begin{table}[ht]
    \centering
    \caption[Journal: Test Suite - Adequacy Data Flow 1]{Test per aumentare la all-use coverage}
    \begin{tabular}{|c|c|c|}
      \hline
      journalDir & JournalIdFilter & Risultato Atteso \\
      \hline
      {Directory con un log con id 2 e un log con id 1} & {Filtro sempre true} & [1, 2] \\
      \hline
    \end{tabular}
    \label{tab:ADF2ListJournalIds}
  \end{table}

%Tabelle FileInfo --------------------------------------------------------

\begin{table}[ht]
  \centering
  \caption[FileInfo: Boundary Analysis 1]{Boundary Analysis metodo readHeader}
  \begin{tabular}{|l|l|l|}
  \hline
  \multicolumn{1}{|c|}{Magic Bytes} & \multicolumn{1}{|c|}{Master Key} & \multicolumn{1}{|c|}{Len of the master key}\\
  \hline
  \{valido\} = BKLE & \{master key di 0 byte\} = new byte[] & \{= len effettiva \} = len effettiva \\
  \{non valido\} = BKLU  & \{master key di \textgreater 0 byte\} = new byte[1] & \{\textless len effettiva\} = len effettiva - 1 \\
   & & \{\textgreater len effettiva\} = len effettiva + 1 \\
  \hline
  \end{tabular}
  \label{tab:boundaryAnalyisReadHeader1}
\end{table}

\begin{table}[ht]
  \centering
  \caption[FileInfo: Boundary Analysis 2]{Boundary Analysis metodo readHeader}
  \begin{tabular}{|l|l|}
  \hline
  \multicolumn{1}{|c|}{State} & \multicolumn{1}{|c|}{Version} \\
  \hline
  \{fenced\} = 1 & \{versione 0\} = 0 \\
  \{non fenced\} = 0 & \{versione 1\} = 1\\
  \hline
  \end{tabular}
  \label{tab:boundaryAnalyisReadHeader2}
\end{table}

\begin{table}[ht]
  \centering
  \caption[FileInfo: Test Suite - Category Partition]{Test Suite derivante dalla category partition e dalla boundary analysis}
  \begin{tabular}{|l|l|l|l|l|l|}
    \hline
    \textbf{Magic Bytes} & \textbf{Master key} & \textbf{Len of master key}  & \textbf{State} & \textbf{Version} & \textbf{Risultato Atteso} \\
    \hline
    BKLE & new byte[1] & 1 & 0 & 1 & Success \\
    BKLE & new byte[1] & 2 & 0 & 1 & Exception \\
    BKLE & new byte[1] & 0 & 0 & 1 & Exception \\
    BKLE & new byte[0] & -1 & 0 & 0 & Success \\
    BKLE & new byte[0] & 0 & 0 & 0 & Success \\
    BKLE & new byte[0] & 1 & 0 & 0 & Exception \\
    BKLU & new byte[1] & 1 & 0 & 1 & Exception \\
    \hline
  \end{tabular}
  \label{tab:categoryPartition1ReadHeader}
\end{table}




\begin{table}[ht]
  \centering
  \caption[FileInfo: Test Suite - Adequacy Control Flow]{Test Suite derivante dall'incremento dopo Jacoco}
  \begin{tabular}{|l|l|l|l|l|l|l|}
    \hline
    \textbf{Magic Bytes} & \textbf{Master key} & \textbf{Len of master key}  & \textbf{State} & \textbf{Version} & \textbf{BufLength} & \textbf{Risultato Atteso} \\
    \hline
    BKLE & new byte[1] & 1 & 0 & 1 & 0 & Success \\
    BKLE & new byte[1] & 2 & 0 & 1 & 0 & Exception \\
    BKLE & new byte[1] & 0 & 0 & 1 & 0 & Exception \\
    BKLE & new byte[0] & -1 & 0 & 0 & 0 & Success \\
    BKLE & new byte[0] & 0 & 0 & 0 & 0 & Success \\
    BKLE & new byte[0] & 1 & 0 & 0 & 0 & Exception \\
    BKLU & new byte[1] & 1 & 0 & 1 & 0 & Exception \\
    BKLE & new byte[1] & 1 & 0 & 1 & 16 & Success \\
    BKLE & new byte[1] & 1 & 0 & 1 & 15 & Exception \\
    BKLE & new byte[1] & 1 & 0 & 1 & -1 & Exception \\
    \hline
  \end{tabular}
  \label{tab:TestSuiteReadHeader2}
\end{table}

\begin{table}[ht]
  \centering
  \caption[FileInfo: Test Suite - Adequacy Data Flow]{Test Suite derivante dall'incremento dopo Badua}
  \begin{tabular}{|l|l|l|l|l|l|l|}
    \hline
    \textbf{Magic Bytes} & \textbf{Master key} & \textbf{Len of master key}  & \textbf{State} & \textbf{Version} & \textbf{BufLength} & \textbf{Risultato Atteso} \\
    \hline
    BKLE & new byte[1] & 1 & 0 & 1 & 0 & Success \\
    BKLE & new byte[1] & 2 & 0 & 1 & 0 & Exception \\
    BKLE & new byte[1] & 0 & 0 & 1 & 0 & Exception \\
    BKLE & new byte[0] & -1 & 0 & 0 & 0 & Success \\
    BKLE & new byte[0] & 0 & 0 & 0 & 0 & Success \\
    BKLE & new byte[0] & 1 & 0 & 0 & 0 & Exception \\
    BKLU & new byte[1] & 1 & 0 & 1 & 0 & Exception \\
    BKLE & new byte[1] & 1 & 0 & 1 & 16 & Success \\
    BKLE & new byte[1] & 1 & 0 & 1 & 15 & Exception \\
    BKLE & new byte[1] & 1 & 0 & 1 & -1 & Exception \\
    BKLE & new byte[1] & 1 & 0 & 2 & -1 & Exception \\
    \hline
  \end{tabular}
  \label{tab:ADF1ReadHeader}
\end{table}


%Tabelle CreateRecord --------------------------------------------------------

\begin{table}[ht]
  \centering
  \caption[Schema - Category Partition]{Category Partition metodo createRecord}
  \begin{tabular}{|l|l|l|l|l|}
  \hline
  \multicolumn{5}{|c|}{Category Partition CreateRecord}\\
  \hline
  \multicolumn{1}{|c|}{name} & \multicolumn{1}{|c|}{doc} & \multicolumn{1}{|c|}{namespace} & 
  \multicolumn{1}{|c|}{isError} & \multicolumn{1}{|c|}{fields} \\
  \hline
  \{null\} & \{null\} & \{null\} & \{true\} & \{null\} \\
  \{stringa vuota\} & \{stringa vuota\} & \{stringa vuota\} & \{false\} & \{array vuoto\} \\
  \{stringa non vuota\} & \{stringa non vuota\} & \{stringa non vuota\} & & \{array 1 elemento\} \\
  & & & & \{array \textgreater 1 elementi\} \\
  \hline
  \end{tabular}
  \label{tab:categoryPartitionCreateRecord}
\end{table}

\begin{table}[ht]
  \centering
  \caption[Schema - Category Partition]{Category Partition metodo createRecord}
  \begin{tabular}{|l|l|l|l|l|}
  \hline
  \multicolumn{1}{|c|}{\textbf{name}} & \multicolumn{1}{|c|}{\textbf{doc}} & \multicolumn{1}{|c|}{\textbf{namespace}} & 
  \multicolumn{1}{|c|}{\textbf{isError}} & \multicolumn{1}{|c|}{\textbf{fields}} \\
  \hline
  null & null & null & true & null \\
  \hdashline[4pt/2pt]
  " " & " " & " " & false & [] \\
  \hdashline[4pt/2pt]
  "test" & "test" & "test" & & [field] \\
  \hdashline[4pt/2pt]
  & & & & [field1, field2] \\
  \hline
  \end{tabular}
  \label{tab:BoundaryAnalysisCreateRecord}
\end{table}

\begin{table}[ht]
  \centering
  \caption[CreateRecord: Test Suite - Category partition]{Test Suite derivante dalla category partition e dalla boundary analysis}
  \begin{tabular}{|l|l|l|l|l|l|}
    \hline
    \textbf{Name} & \textbf{Doc} & \textbf{Namespace}  & \textbf{IsError} & \textbf{Fields} & \textbf{Risultato Atteso} \\
    \hline
    "test" & "test" & "test" & False & [Field1] & Success \\
    "test" & "test" & "test" & False & [Field1, Field2] & Success \\
    "" & "" & "" & True & [Field1, Field2] & Exception \\
    null & null & null & False & [Field1] & Exception \\
    "test" & "test" & "test" & False & null & Exception \\
    "test" & "test" & "test" & False & [] & Excpetion \\

    \hline
  \end{tabular}
  \label{tab:categoryPartition1CreateRecord}
\end{table}


\begin{table}[ht]
  \centering
  \caption[CreateRecord: Test Suite - Adequacy Control Flow]{Test Suite derivante dall'incremento dopo Jacoco}
  \begin{tabular}{|l|l|l|l|l|l|}
    \hline
    \textbf{Name} & \textbf{Doc} & \textbf{Namespace}  & \textbf{IsError} & \textbf{Fields} & \textbf{Risultato Atteso} \\
    \hline
    "test" & "test" & "test" & False & [Field1] & Success \\
    "test" & "test" & "test" & False & [Field1, Field2] & Success \\
    "" & "" & "" & True & [Field1, Field2] & Exception \\
    null & null & null & False & [Field1] & Exception \\
    "test" & "test" & "test" & False & null & Exception \\
    "test" & "test" & "test" & False & [] & Excpetion \\
    "test" & "test" & "test" & False & [Field3*] & Excpetion \\
    \hline
  \end{tabular}
   \\$\ast$Field3 è un field con position = -1
  \label{tab:Jacoco1CreateRecord}
\end{table}

\begin{table}[ht]
  \centering
  \caption[CreateRecord: Test Suite - Adequacy Control Flow]{Test Suite derivante dall'incremento dopo Badua}
  \begin{tabular}{|l|l|l|l|l|l|}
    \hline
    \textbf{Name} & \textbf{Doc} & \textbf{Namespace}  & \textbf{IsError} & \textbf{Fields} & \textbf{Risultato Atteso} \\
    \hline
    "test" & "test" & "test" & False & [Field1] & Success \\
    "test" & "test" & "test" & False & [Field1, Field2] & Success \\
    "" & "" & "" & True & [Field1, Field2] & Exception \\
    null & null & null & False & [Field1] & Exception \\
    "test" & "test" & "test" & False & null & Exception \\
    "test" & "test" & "test" & False & [] & Excpetion \\
    "test" & "test" & "test" & False & [Field3*] & Excpetion \\
    "test" & "test" & "test" & False & [Field1, Field1] & Excpetion \\
    \hline
  \end{tabular}
   \\$\ast$Field3 è un field con position = -1
  \label{tab:Badua1CreateRecord}
\end{table}
  
\begin{table}[ht]
  \centering
  \caption[CreateRecord: Test Suite - Mutation Testing]{Test Suite derivante dall'incremento dopo Pit}
  \begin{tabular}{|l|l|l|l|l|l|}
    \hline
    \textbf{Name} & \textbf{Doc} & \textbf{Namespace}  & \textbf{IsError} & \textbf{Fields} & \textbf{Risultato Atteso} \\
    \hline
    "test" & "test" & "test" & False & [Field1] & Object(Schema) \\
    "test" & "test" & "test" & False & [Field1, Field2] & Object(Schema) \\
    "" & "" & "" & True & [Field1, Field2] & Exception \\
    null & null & null & False & [Field1] & Exception \\
    "test" & "test" & "test" & False & null & Exception \\
    "test" & "test" & "test" & False & [] & Excpetion \\
    "test" & "test" & "test" & False & [Field3*] & Excpetion \\
    "test" & "test" & "test" & False & [Field1, Field1] & Excpetion \\
    \hline
  \end{tabular}
   \\$\ast$Field3 è un field con position = -1
  \label{tab:PitCreateRecord1}
\end{table}


%Tabelle SchemaCompatibility --------------------------------------------------------

\begin{table}[ht]
  \centering
  \caption[SchemaCompatibility: Test Suite - Category Partition]{Test Suite derivante dalla category partition e dalla boundary analysis}
  \begin{tabular}{|c|c|c|}
    \hline
    Reader & Writer & Valore atteso \\
    \hline
    Schema tipo int & Schema tipo int & True \\
    Schema tipo Record & Schema tipo int & False \\
    Schema tipo int & Schema tipo String & False \\
    \hline
  \end{tabular}
  \label{tab:TestSuiteSchemaCompatibility}
\end{table}
  

%Figure Journal --------------------------------------------------------
  \clearpage
  \begin{figure}
    \centering
    \begin{subfigure}[a]{0.4\linewidth}
      \includegraphics[width=\linewidth]{./images/journal/listJournalIds.jpg}
      \caption{Functional diagram}
    \end{subfigure}
    \begin{subfigure}[b]{0.4\linewidth}
      \includegraphics[width=\linewidth]{./images/journal/CFGlistJournalIds.jpg}
    \caption{Control Flow Graph}
    \end{subfigure}
    \caption{Diagrammi di listJournalIds}
    \label{fig:listJournalIdsCFG}
  \end{figure}

  \begin{figure}
    \includegraphics[width=\linewidth]{./images/journal/JacocoCoveragelistJournalIds1.png}
    \caption{Jacoco coverage dilistJournalIds}
    \label{fig:listJournalIds_jacoco}
  \end{figure}

  \begin{figure}
    \includegraphics[width=\linewidth]{./images/journal/MissedBranchListJournalIds.png}
    \caption{Jacoco coverage dilistJournalIds}
    \label{fig:listJournalIds_jacoco2}
  \end{figure}

  \begin{figure}
    \includegraphics[width=\linewidth]{./images/journal/JacocoCoveragelistJournalIds2.png}
    \caption{Jacoco coverage dilistJournalIds}
    \label{fig:listJournalIds_jacoco3}
  \end{figure}

  \begin{figure}
    \includegraphics[width=\linewidth]{./images/journal/code1.png}
    \caption{Codice sorgente di JournalTest}
    \label{fig:code1}
  \end{figure}

  \begin{figure}
    \includegraphics[width=\linewidth]{./images/journal/BaduaCoveragelistJournalIds1.png}
    \caption{Badua coverage dilistJournalIds}
    \label{fig:listJournalIds_badua}
  \end{figure}

  \begin{figure}
    \includegraphics[width=\linewidth]{./images/journal/BaduaCoveragelistJournalIds2.png}
    \caption{Badua coverage dilistJournalIds}
    \label{fig:listJournalIds_badua2}
  \end{figure}

  \begin{figure}
    \includegraphics[width=\linewidth]{./images/journal/JacocoCoveragelistJournalIds3.png}
    \caption{Jacoco coverage dilistJournalIds}
    \label{fig:listJournalIds_jacoco4}
  \end{figure}

  \begin{figure}
    \includegraphics[width=\linewidth]{./images/journal/PitCoverageListJournalIds1.png}
    \caption{Pitest coverage dilistJournalIds}
    \label{fig:listJournalIds_pitest}
  \end{figure}

  \begin{figure}
    \includegraphics[width=\linewidth]{./images/journal/PitCoverageListJournalIds2.png}
    \caption{Mutazioni rilevate da Pitest}
    \label{fig:listJournalIds_pitest2}
  \end{figure}

  \begin{figure}
    \includegraphics[width=\linewidth]{./images/journal/PitMutation1.png}
    \caption{Mutazione inserita nel codice sorgente di Bookkeeper}
    \label{fig:PitMutation1}
  \end{figure}

  \begin{figure}
    \includegraphics[width=\linewidth]{./images/journal/code2.png}
    \caption{Codice sorgente di JournalTest aggiornato con il mock}
    \label{fig:code2}
  \end{figure}

  \begin{figure}
    \includegraphics[width=\linewidth]{./images/file_info/JacocoCoveragereadHeader1.png}
    \caption{Jacoco coverage readHeader}
    \label{fig:JacocoCoveragereadHeader1}
  \end{figure}
  \begin{figure}
    \includegraphics[width=\linewidth]{./images/file_info/Code1ReadHeader.png}
    \caption{Codice sorgente di FileInfoTest}
    \label{fig:Code1ReadHeader}
  \end{figure}

  \begin{figure}
    \includegraphics[width=\linewidth]{./images/file_info/TestFailsReadHeader.png}
    \caption{Fallimento test readHeader}
    \label{fig:TestFailsReadHeader}
  \end{figure}  

  \begin{figure}
    \includegraphics[width=\linewidth]{./images/file_info/JacocoCoveragereadHeader2.png}
    \caption{Jacoco coverage readHeader}
    \label{fig:JacocoCoveragereadHeader2}
  \end{figure}

  \begin{figure}
    \includegraphics[width=\linewidth]{./images/file_info/JacocoCoveragereadHeader3.png}
    \caption{Jacoco coverage readHeader}
    \label{fig:JacocoCoveragereadHeader3}
  \end{figure}

  \begin{figure}
    \includegraphics[width=\linewidth]{./images/file_info/BaduaCoverageReadHeader1.png}
    \caption{Badua coverage readHeader}
    \label{fig:BaduaCoverageReadHeader1}
  \end{figure}

  \begin{figure}
    \includegraphics[width=\linewidth]{./images/file_info/BaduaCoverageReadHeader2.png}
    \caption{Def-use not covered}
    \label{fig:BaduaCoverageReadHeader2}
  \end{figure}

  \begin{figure}
    \includegraphics[width=\linewidth]{./images/file_info/BaduaCoverageReadHeader3.png}
    \caption{Def-use covered}
    \label{fig:BaduaCoverageReadHeader3}
  \end{figure}

  \begin{figure}
    \includegraphics[width=\linewidth]{./images/file_info/BaduaCoverageReadHeader4.png}
    \caption{Badua coverage readHeader after test update}
    \label{fig:BaduaCoverageReadHeader4}
  \end{figure}

  \begin{figure}
    \includegraphics[width=\linewidth]{./images/file_info/PitCoverageReadHeader1.png}
    \caption{Pit coverage}
    \label{fig:PitCoverageReadHeader1}
  \end{figure}
  
  \begin{figure}
    \includegraphics[width=\linewidth]{./images/file_info/PitCoverageReadHeader2.png}
    \caption{Pit coverage}
    \label{fig:PitCoverageReadHeader2}
  \end{figure}
  
  \begin{figure}
    \includegraphics[width=\linewidth]{./images/file_info/PitCoverageReadHeader3.png}
    \caption{Pit coverage}
    \label{fig:PitCoverageReadHeader3}
  \end{figure}

  \begin{figure}
    \includegraphics[width=\linewidth]{./images/create_record/Documentation.png}
    \caption{Documentazione Record}
    \label{fig:Documentation}
  \end{figure}

  \begin{figure}
    \includegraphics[width=\linewidth]{./images/create_record/TestFailsCreateRecord.png}
    \caption{Fallimento del 4 e 6 test}
    \label{fig:TestFailsCreateRecord}
  \end{figure}

  \begin{figure}
    \includegraphics[width=\linewidth]{./images/create_record/JacocoCoverage1.png}
    \caption{Jacoco coverage createRecord}
    \label{fig:JacocoCoverageCreateRecord1}
  \end{figure}

  \begin{figure}
    \includegraphics[width=\linewidth]{./images/create_record/JacocoCoverage2.png}
    \caption{Jacoco coverage Record Schema}
    \label{fig:JacocoCoverageCreateRecord2}
  \end{figure}

  \begin{figure}
    \includegraphics[width=\linewidth]{./images/create_record/JacocoCoverage3.png}
    \caption{Jacoco coverage Costruttore Record Schema e setField}
    \label{fig:JacocoCoverageCreateRecord3}
  \end{figure}

  \begin{figure}
    \includegraphics[width=\linewidth]{./images/create_record/JacocoCoverage4.png}
    \caption{Jacoco copertura setField}
    \label{fig:JacocoCoverageCreateRecord4}
  \end{figure}

  \begin{figure}
    \includegraphics[width=\linewidth]{./images/create_record/JacocoCoverage5.png}
    \caption{Jacoco coverage dopo incremento}
    \label{fig:JacocoCoverageCreateRecord5}
  \end{figure}

  \begin{figure}
    \includegraphics[width=\linewidth]{./images/create_record/BaduaCoverage1.png}
    \caption{Badua coverage createRecord}
    \label{fig:BaduaCoverageCreateRecord1}
  \end{figure}

  \begin{figure}
    \includegraphics[width=\linewidth]{./images/create_record/BaduaCoverage2.png}
    \caption{Badua coverage createRecord}
    \label{fig:BaduaCoverageCreateRecord2}
  \end{figure}

  \begin{figure}
    \includegraphics[width=\linewidth]{./images/create_record/PitCoverage1.png}
    \caption{PitCoverage}
    \label{fig:PitMutationCreateRecord1}
  \end{figure}

  \begin{figure}
    \includegraphics[width=\linewidth]{./images/create_record/PitCoverage2.png}
    \caption{Mutazioni rilevate da Pitest}
    \label{fig:PitMutationCreateRecord2}
  \end{figure}

  \begin{figure}
    \includegraphics[width=\linewidth]{./images/create_record/PitCoverage3.png}
    \caption{Mutazioni rilevate da Pitest}
    \label{fig:PitMutationCreateRecord3}
  \end{figure}

  \begin{figure}
    \includegraphics[width=\linewidth]{./images/create_record/PitCoverage4.png}
    \caption{Mutazioni rilevate da Pitest}
    \label{fig:PitMutationCreateRecord4}
  \end{figure}
  \clearpage
  \begin{figure}
    \includegraphics[width=\linewidth]{./images/create_record/PitCoverage5.png}
    \caption{Mutazione in considerazione}
    \label{fig:PitMutationCreateRecord5}
  \end{figure}

  \begin{figure}
    \includegraphics[width=\linewidth]{./images/create_record/PitCoverage6.png}
    \caption{Mutazione in considerazione coperta}
    \label{fig:PitMutationCreateRecord6}
  \end{figure}

  \begin{figure}
    \includegraphics[width=\linewidth]{./images/schema_compatibiity/JacocoCoverage1.png}
    \caption{Coverage Jacoco}
    \label{fig:JacocoCoverageSchemaCompatibility1}
  \end{figure}

  \begin{figure}
    \includegraphics[width=\linewidth]{./images/schema_compatibiity/JacocoCoverage2.png}
    \caption{Coverage Jacoco}
    \label{fig:JacocoCoverageSchemaCompatibility2}
  \end{figure}

  \begin{figure}
    \includegraphics[width=\linewidth]{./images/schema_compatibiity/BaduaCoverage1.png}
    \caption{Coverage Badua}
    \label{fig:BaduaCoverageSchemaCompatibility1}
  \end{figure}

  \begin{figure}
    \includegraphics[width=\linewidth]{./images/schema_compatibiity/PitCoverage1.png}
    \caption{Coverage Pit}
    \label{fig:PitMutationSchemaCompatibility1}
  \end{figure}

  \begin{figure}
    \includegraphics[width=\linewidth]{./images/integration_test/IntegrationTest.png}
    \caption{Codice Integration Test}
    \label{fig:CodeIntegrationTest}
  \end{figure}

  \begin{figure}
    \includegraphics[width=\linewidth]{./images/integration_test/FailsafeReport.png}
    \caption{Report Integration Test}
    \label{fig:ReportIntegrationTest}
  \end{figure}

  
\end{document}
